{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import string\n",
    "import nltk\n",
    "import warnings \n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df  = pd.read_csv('train.csv',encoding='latin-1')\n",
    "df.drop(['ItemID'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>SentimentText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>is so sad for my APL frie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>I missed the New Moon trail...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>omg its already 7:30 :O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>.. Omgaga. Im sooo  im gunna CRy. I'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>i think mi bf is cheating on me!!!   ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sentiment                                      SentimentText\n",
       "0          0                       is so sad for my APL frie...\n",
       "1          0                     I missed the New Moon trail...\n",
       "2          1                            omg its already 7:30 :O\n",
       "3          0            .. Omgaga. Im sooo  im gunna CRy. I'...\n",
       "4          0           i think mi bf is cheating on me!!!   ..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_pattern(input_txt, pattern):\n",
    "    r = re.findall(pattern, input_txt)\n",
    "    for i in r:\n",
    "        input_txt = re.sub(i, '', input_txt)\n",
    "        \n",
    "    return input_txt  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove twitter handles\n",
    "df['CleanSenText'] = np.vectorize(remove_pattern)(df['SentimentText'], \"@[\\w]*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>SentimentText</th>\n",
       "      <th>CleanSenText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>0</td>\n",
       "      <td>so whats the status on next weekend</td>\n",
       "      <td>so whats the status on next weekend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>0</td>\n",
       "      <td>sorry @gigi4462 The Ex Husband has overdosed...</td>\n",
       "      <td>sorry  The Ex Husband has overdosed on his d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>0</td>\n",
       "      <td>Thanks for your definition of throwbie!  Edi...</td>\n",
       "      <td>Thanks for your definition of throwbie!  Edi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>1</td>\n",
       "      <td>Thanks, I need all the help i can get.</td>\n",
       "      <td>Thanks, I need all the help i can get.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>1</td>\n",
       "      <td>- that explains alot.</td>\n",
       "      <td>- that explains alot.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>1</td>\n",
       "      <td>There's going to be a Heathers sequel.  Wino...</td>\n",
       "      <td>There's going to be a Heathers sequel.  Wino...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sentiment                                      SentimentText  \\\n",
       "109          0                so whats the status on next weekend   \n",
       "110          0    sorry @gigi4462 The Ex Husband has overdosed...   \n",
       "111          0    Thanks for your definition of throwbie!  Edi...   \n",
       "112          1             Thanks, I need all the help i can get.   \n",
       "113          1                              - that explains alot.   \n",
       "114          1    There's going to be a Heathers sequel.  Wino...   \n",
       "\n",
       "                                          CleanSenText  \n",
       "109                so whats the status on next weekend  \n",
       "110    sorry  The Ex Husband has overdosed on his d...  \n",
       "111    Thanks for your definition of throwbie!  Edi...  \n",
       "112             Thanks, I need all the help i can get.  \n",
       "113                              - that explains alot.  \n",
       "114    There's going to be a Heathers sequel.  Wino...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[109:115] \n",
    "\n",
    "# used 109:115 because includes @user text; verifies @ were removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove special characters, punctuations\n",
    "df['CleanSenText'] = df['CleanSenText'].str.replace(\"[^a-zA-Z0-9#]\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>SentimentText</th>\n",
       "      <th>CleanSenText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>is so sad for my APL frie...</td>\n",
       "      <td>is so sad for my APL frie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>I missed the New Moon trail...</td>\n",
       "      <td>I missed the New Moon trail...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>omg its already 7:30 :O</td>\n",
       "      <td>omg its already 7 30  O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>.. Omgaga. Im sooo  im gunna CRy. I'...</td>\n",
       "      <td>Omgaga  Im sooo  im gunna CRy  I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>i think mi bf is cheating on me!!!   ...</td>\n",
       "      <td>i think mi bf is cheating on me      ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sentiment                                      SentimentText  \\\n",
       "0          0                       is so sad for my APL frie...   \n",
       "1          0                     I missed the New Moon trail...   \n",
       "2          1                            omg its already 7:30 :O   \n",
       "3          0            .. Omgaga. Im sooo  im gunna CRy. I'...   \n",
       "4          0           i think mi bf is cheating on me!!!   ...   \n",
       "\n",
       "                                        CleanSenText  \n",
       "0                       is so sad for my APL frie...  \n",
       "1                     I missed the New Moon trail...  \n",
       "2                            omg its already 7 30  O  \n",
       "3               Omgaga  Im sooo  im gunna CRy  I ...  \n",
       "4           i think mi bf is cheating on me      ...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will tokenize all the cleaned tweets in our dataset. Tokens are individual terms or words, and tokenization is the process of splitting a string of text into tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "tt = TweetTokenizer()\n",
    "\n",
    "label=list(df.Sentiment)\n",
    "text=df['CleanSenText'].apply(tt.tokenize)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(text, label, test_size=0.2, random_state=628)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18068    [oxygen, Love, the, atmosphere, http, myloc, m...\n",
       "31602    [HAHAH, YES, he, s, so, cute, and, he, has, th...\n",
       "76299                                [we, r, all, special]\n",
       "73950    [Yes, that, s, different, Unless, they, have, ...\n",
       "520      [I, feel, irresponsible, and, sort, of, horrib...\n",
       "Name: CleanSenText, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(text)\n",
    "vocab = tokenizer.word_index\n",
    "\n",
    "X_train_word_ids = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_word_ids = tokenizer.texts_to_sequences(X_test)\n",
    "x_train = pad_sequences(X_train_word_ids, maxlen=50)\n",
    "x_test= pad_sequences(X_test_word_ids, maxlen=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,  6447,    46,     3,\n",
       "        7409,    65,  1109,    15, 31660], dtype=int32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv1D, GlobalMaxPooling1D\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "import numpy as np\n",
    "from keras.optimizers import Adam\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "num_words = 125000\n",
    "embedding_matrix = np.zeros((num_words, 50))\n",
    "\n",
    "e1 = Embedding(num_words, 50, input_length=50, trainable=True)\n",
    "e2 = Embedding(num_words, 50, input_length=50, trainable=True)\n",
    "e3 = Embedding(num_words, 50, input_length=50, trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.utils\n",
    "y_train_cat = keras.utils.to_categorical(y_train)\n",
    "y_test_cat = keras.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/.local/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/ubuntu/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 50, 50)            6250000   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 50, 50)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 49, 100)           10100     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 49, 100)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 48, 50)            10050     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 48, 50)            0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                3264      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 6,273,544\n",
      "Trainable params: 6,273,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:From /home/ubuntu/.local/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /home/ubuntu/.local/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Train on 79991 samples, validate on 19998 samples\n",
      "Epoch 1/5\n",
      " - 64s - loss: 0.5751 - acc: 0.6899 - val_loss: 0.5248 - val_acc: 0.7457\n",
      "Epoch 2/5\n",
      " - 63s - loss: 0.4805 - acc: 0.7719 - val_loss: 0.5141 - val_acc: 0.7464\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd9b52b3cc0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I did try optimizer=RMSprop(), sgd, adam\n",
    "# also tried learning rate of 0.1, 0.01, 0.001 \n",
    "# also tried categorizing the y\n",
    "# per the instructions here: https://stackoverflow.com/questions/37213388/keras-accuracy-does-not-change\n",
    "\n",
    "#model_cnn.reset_states() #clear previous model weights\n",
    "\n",
    "model_cnn = Sequential()\n",
    "model_cnn.add(e1)\n",
    "model_cnn.add(Dropout(.5))\n",
    "model_cnn.add(Conv1D(filters=100, kernel_size=2, padding='valid', activation='relu', strides=1))\n",
    "model_cnn.add(Dropout(.5))\n",
    "model_cnn.add(Conv1D(filters=50, kernel_size=2, padding='valid', activation='relu', strides=1))\n",
    "model_cnn.add(Dropout(.5))\n",
    "model_cnn.add(GlobalMaxPooling1D())\n",
    "model_cnn.add(Dense(64, activation='relu'))\n",
    "model_cnn.add(Dropout(.5))\n",
    "model_cnn.add(Dense(2, activation='sigmoid'))\n",
    "adamop=Adam(lr=0.001) \n",
    "model_cnn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model_cnn.summary())\n",
    "#Changed y to _cat below to try to fix repeating val_acc\n",
    "model_cnn.fit(x_train, y_train_cat, validation_data=(x_test, y_test_cat), epochs=5, \n",
    "              batch_size=64, verbose=2, callbacks=[EarlyStopping(monitor='val_acc',min_delta=0.001)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 74.64%\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation of the model\n",
    "score_cnn = model_cnn.evaluate(x_test, y_test_cat, verbose=2)\n",
    "print(\"Accuracy: %.2f%%\" % (score_cnn[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import RNN\n",
    "from keras.layers import SimpleRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 50, 50)            6250000   \n",
      "_________________________________________________________________\n",
      "simple_rnn_1 (SimpleRNN)     (None, 128)               22912     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 6,281,233\n",
      "Trainable params: 6,281,233\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 79991 samples, validate on 19998 samples\n",
      "Epoch 1/5\n",
      " - 98s - loss: 0.5096 - acc: 0.7456 - val_loss: 0.4693 - val_acc: 0.7703\n",
      "Epoch 2/5\n",
      " - 97s - loss: 0.3863 - acc: 0.8268 - val_loss: 0.5067 - val_acc: 0.7695\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd9b403f860>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model_rnn.reset_states() #clear previous model weights\n",
    "\n",
    "# create the model\n",
    "model_rnn = Sequential()\n",
    "model_rnn.add(e2)\n",
    "model_cnn.add(Dropout(.5))\n",
    "model_rnn.add(SimpleRNN(128, activation='relu'))\n",
    "model_rnn.add(Dense(64, activation='relu'))\n",
    "model_cnn.add(Dropout(.5))\n",
    "model_rnn.add(Dense(1, activation='sigmoid'))\n",
    "adamop=Adam(lr=0.001) \n",
    "model_rnn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model_rnn.summary())\n",
    "model_rnn.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=5, batch_size=64, verbose=2,callbacks=[EarlyStopping(monitor='val_acc',min_delta=0.01)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 76.95%\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation of the model\n",
    "score_rnn = model_rnn.evaluate(x_test, y_test, verbose=2)\n",
    "print(\"Accuracy: %.2f%%\" % (score_rnn[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 50, 50)            6250000   \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 50, 50)            0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100)               60400     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 6,310,501\n",
      "Trainable params: 6,310,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 79991 samples, validate on 19998 samples\n",
      "Epoch 1/5\n",
      " - 160s - loss: 0.5225 - acc: 0.7388 - val_loss: 0.4774 - val_acc: 0.7665\n",
      "Epoch 2/5\n",
      " - 152s - loss: 0.4311 - acc: 0.8023 - val_loss: 0.4752 - val_acc: 0.7676\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd98845d668>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model_lstm.reset_states()\n",
    "\n",
    "# create the model\n",
    "model_lstm = Sequential()\n",
    "model_lstm.add(e3)\n",
    "model_lstm.add(Dropout(0.5))\n",
    "model_lstm.add(LSTM(100))\n",
    "model_lstm.add(Dropout(0.5))\n",
    "model_lstm.add(Dense(1, activation='sigmoid'))\n",
    "adamop=Adam(lr=0.001) \n",
    "model_lstm.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model_lstm.summary())\n",
    "model_lstm.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=5, batch_size=64, verbose=2,callbacks=[EarlyStopping(monitor='val_acc',min_delta=.01)])\n",
    "#model_lstm.fit(x_train, y_train, validation_data=(x_train, y_train), validation_split = 0.2, epochs=5, batch_size=64, verbose=2,callbacks=[EarlyStopping(monitor='val_acc',min_delta=.01)])\n",
    "#model_lstm.fit(x_train, y_train, epochs=5, batch_size=64, verbose=2, validation_split = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19998/19998 [==============================] - 4s 225us/step\n",
      "Accuracy: 76.76%\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation of the model\n",
    "score_lstm = model_lstm.evaluate(x_test, y_test, verbose=1)\n",
    "print(\"Accuracy: %.2f%%\" % (score_lstm[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
